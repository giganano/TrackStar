{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa147aab-bf11-4f5a-aa0c-64b6848834c6",
   "metadata": {},
   "source": [
    "# Your First TrackStar Program\n",
    "\n",
    "This tutorial presents a simple TrackStar program to familiarize new users with its usage.\n",
    "We'll construct a sample of mock data from a known input model, storing the data as a ``trackstar.sample`` object and the model predictions as a ``trackstar.track`` object.\n",
    "We'll then compute the likelihood function with a few different settings for the same known input model.\n",
    "\n",
    "We'll start by simply importing TrackStar and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b2b879-ea47-4765-b644-160ded8406bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesjohnson/Work/Research/lib/public-dev/TrackStar/trackstar/version.py:91: VersionWarning: Using a development version of TrackStar. Be advised that the features in development may exhibit buggy behavior and/or numerical artifacts. We encourage consulting with TrackStar developers.\n",
      "  if self.dev is not None: warnings.warn(\"\"\"\\\n",
      "/Users/jamesjohnson/Work/Research/lib/public-dev/TrackStar/trackstar/version.py:95: VersionWarning: Using an un-released version of TrackStar.\n",
      "  if not self.isreleased: warnings.warn(\"\"\"\\\n"
     ]
    }
   ],
   "source": [
    "import trackstar\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f493ac1-21bd-4e56-a89d-b220f557266b",
   "metadata": {},
   "source": [
    "## A Mock Data Sample\n",
    "\n",
    "Let's set up our mock sample.\n",
    "For illustrative purposes, we'll keep it simple and straight-forward.\n",
    "\n",
    "We'll take $N = 100$ points along the line $x = y = z$ in 3-dimensional space, following an intrinsic distribution that follows a Gaussian centered on zero (i.e. $\\langle x \\rangle = \\langle y \\rangle = \\langle z \\rangle = 0$) with a standard deviation of $\\sigma = 1$.\n",
    "To demonstrate TrackStar's user-friendliness in fitting non-uniform samples, we'll let only *half* of our data vectors have measurements of $z$.\n",
    "Such instances may arise, e.g., within astrophysics, when not every star has a reliable age measurement.\n",
    "\n",
    "We'll let $x$ and $y$ have measurement uncertainties of $\\sigma_x = \\sigma_y = 0.1$, while each measurement of $z$ will have a more substantial uncertainty of $\\sigma_z = 0.3$.\n",
    "In this instance, $z$ is a stand-in for some quantity that may be challenging to measure.\n",
    "In real samples, there may be only a handful of coarse measurements, but the information is nonetheless useful or valuable.\n",
    "\n",
    "Before bringing in TrackStar, let's set up the numbers themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2353dbe6-9635-4e7e-9263-a229de512948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the underlying sample with no measurement uncertainty\n",
    "true_values = np.random.normal(loc = 0, scale = 1, size = 100)\n",
    "\n",
    "# the sampled true values perturbed my measurement uncertainty for x and y\n",
    "x = true_values + np.random.normal(loc = 0, scale = 0.1, size = 100)\n",
    "y = true_values + np.random.normal(loc = 0, scale = 0.1, size = 100)\n",
    "\n",
    "# half of the z measurements are missing\n",
    "z = np.array([true_values[i] + np.random.normal(\n",
    "    loc = 0, scale = 0.3) if i % 2 else float(\"nan\") for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f3cfd-eb52-43c0-b438-aaf2e0225eb6",
   "metadata": {},
   "source": [
    "To construct these arrays, we made use of NumPy's automatic component-wise addition when the arrays are the same length.\n",
    "Let's inspect the first few elements of each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fa4654-5635-4aae-9f46-57098963862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [-0.2730993   0.11536843 -1.35475868  1.3459729   0.23392896]\n",
      "y:  [-0.33890861 -0.03828595 -1.4841992   1.3130942   0.27316195]\n",
      "z:  [        nan -0.3415485          nan  1.09354396         nan]\n"
     ]
    }
   ],
   "source": [
    "print(\"x: \", x[:5])\n",
    "print(\"y: \", y[:5])\n",
    "print(\"z: \", z[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a716539-bcde-4c89-ac7a-6ba5c51ccf0b",
   "metadata": {},
   "source": [
    "TrackStar recognizes ``NaN`` values as missing data, so every other value of $z$ is assigned ``NaN`` accordingly (more on this below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec1291-daa1-4c8d-b2dd-5187bc080962",
   "metadata": {},
   "source": [
    "### ``trackstar.sample``: The Workhorse for Storing Data\n",
    "\n",
    "The workhorse for storing data in TrackStar is ``sample``, which stores data vectors in a dictionary-like manner, using string labels to denote different measured quantities.\n",
    "The most straight-forward way to construct one is to give it a dictionary containing the arrays of each measured quantity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c01fae-40c0-4f9b-b092-4b8ae22ae991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample(\n",
      "    N = 100\n",
      "    x --------------> [-2.7310e-01,  1.1537e-01, -1.3548e+00, ...,  2.4290e+00,  5.8152e-01,  9.5089e-01]\n",
      "    y --------------> [-3.3891e-01, -3.8286e-02, -1.4842e+00, ...,  2.4613e+00,  6.4115e-01,  9.0541e-01]\n",
      "    z --------------> [ nan       , -3.4155e-01,  nan       , ...,  2.2425e+00,  nan       ,  6.3844e-01]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = trackstar.sample({\n",
    "    \"x\": x,\n",
    "    \"y\": y,\n",
    "    \"z\": z,\n",
    "    \"err_x\": 100 * [0.1],\n",
    "    \"err_y\": 100 * [0.1],\n",
    "    \"err_z\": [0.3 if i % 2 else float(\"nan\") for i in range(100)],\n",
    "})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3fdb30-b1e6-4da6-98a5-b06b2f1eb8f0",
   "metadata": {},
   "source": [
    "There are additional ways to load your data into a ``sample`` and additional features that we do not cover in this tutorial.\n",
    "More examples can be found in out [samples](samples.ipynb) tutorial.\n",
    "\n",
    "This call returns a ``sample`` object, a data structure with similar behavior to the ``pandas DataFrame`` in that it can be indexed with both row number and column label.\n",
    "By calling the ``.keys()`` instance method, we are able to access the labels that we have given our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bea36af-da35-4b1c-b767-fd82e1e84310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95587103-f985-4cfe-aebd-2d5833594466",
   "metadata": {},
   "source": [
    "TrackStar has recognized the measurement uncertainties for what they are based on their labels in our call to ``trackstar.sample`` above (see [below](#where-the-measurement-uncertainties-reside) for information on where they've gone).\n",
    "\n",
    "We can also access the number of data vectors in our sample by calling either ``len(data)`` or ``data.size``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca44d4ac-40bf-4b45-b13b-991c5c6e305b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21949bac-eee6-4898-878d-7a7c1ce7db24",
   "metadata": {},
   "source": [
    "By indexing with a row number, we get an individual data vector with all of its components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5bb126-b819-45ff-b4b5-464391ed04f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datum(\n",
      "    x --------------> -2.7310e-01\n",
      "    y --------------> -3.3891e-01\n",
      ")\n",
      "datum(\n",
      "    x --------------> 1.1537e-01\n",
      "    y --------------> -3.8286e-02\n",
      "    z --------------> -3.4155e-01\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29eb2c9-ebd1-4a8a-9bca-5f34797b1e7a",
   "metadata": {},
   "source": [
    "Note that the ``NaN`` value we entered for our zero'th data vector does not show up here, because TrackStar has recognized this as an indication that there is no measurement.\n",
    "There are some caveats associated with this behavior, which we recommend new users familiarize themselves with (see the [note on NaNs in TrackStar](#a-note-on-nans-in-trackstar) below).\n",
    "In short, TrackStar does not allow ``NaN`` values to be changed to numerical values, and vice versa.\n",
    "\n",
    "---\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "While new data vectors can be added to an existing ``sample`` (by calling ``sample.add_datum``), existing data vectors are not allowed to change size.\n",
    "All vector components must be included upon creation of the data vector.\n",
    "If a given data vector does not already have a measurement for a particular quantity, then item assignment for that quantity will raise a ``KeyError``.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18971d-1f95-465e-805e-69da6d9e8def",
   "metadata": {},
   "source": [
    "Item assignment can be achieved with familiar standard procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6682f867-2590-4b4b-8f4c-00dc0f13f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datum(\n",
      "    x --------------> 0.0000e+00\n",
      "    y --------------> -3.3891e-01\n",
      ")\n",
      "datum(\n",
      "    x --------------> 1.0000e+00\n",
      "    y --------------> -3.3891e-01\n",
      ")\n",
      "datum(\n",
      "    x --------------> 2.0000e+00\n",
      "    y --------------> -3.3891e-01\n",
      ")\n",
      "datum(\n",
      "    x --------------> -2.7310e-01\n",
      "    y --------------> -3.3891e-01\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "old_value = data[\"x\", 0] # for re-assignment near the end of this cell\n",
    "data[\"x\", 0] = 0\n",
    "print(data[0])\n",
    "data[0, \"x\"] = 1\n",
    "print(data[0])\n",
    "data[\"x\"][0] = 2\n",
    "print(data[0])\n",
    "data[0][\"x\"] = old_value\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9fae5-075d-4364-82f0-8211d1f9b211",
   "metadata": {},
   "source": [
    "The ``sample`` can also be sliced to take different subsamples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deedb5f4-cee3-41ee-9ff1-dab8692ca664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample(\n",
      "    N = 5\n",
      "    x --------------> [-2.7310e-01,  1.1537e-01, -1.3548e+00,  1.3460e+00,  2.3393e-01]\n",
      "    y --------------> [-3.3891e-01, -3.8286e-02, -1.4842e+00,  1.3131e+00,  2.7316e-01]\n",
      "    z --------------> [ nan       , -3.4155e-01,  nan       ,  1.0935e+00,  nan       ]\n",
      ")\n",
      "sample(\n",
      "    N = 5\n",
      "    x --------------> [ 1.3261e+00, -1.6912e-03, -7.3337e-01,  7.3152e-01, -5.6022e-02]\n",
      "    y --------------> [ 1.1857e+00, -8.2832e-02, -6.9463e-01,  7.5656e-01, -3.9798e-02]\n",
      "    z --------------> [ nan       , -1.8502e-02,  nan       ,  1.3787e+00,  nan       ]\n",
      ")\n",
      "sample(\n",
      "    N = 50\n",
      "    x --------------> [-2.7310e-01, -1.3548e+00,  2.3393e-01, ...,  3.5019e-01, -5.1588e-01,  5.8152e-01]\n",
      "    y --------------> [-3.3891e-01, -1.4842e+00,  2.7316e-01, ...,  2.2743e-01, -3.1713e-01,  6.4115e-01]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data[:5])\n",
    "print(data[20:25])\n",
    "print(data[::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f0950-6a76-428c-906c-652152be5371",
   "metadata": {},
   "source": [
    "By indexing with a column label, we get the measurements of that quantity for each data vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7c2fa5-4b59-496d-80a8-5f2263cdc9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linked_array([-2.7310e-01,  1.1537e-01, -1.3548e+00, ...,  2.4290e+00,  5.8152e-01,  9.5089e-01])\n",
      "linked_array([ nan       , -3.4155e-01,  nan       , ...,  2.2425e+00,  nan       ,  6.3844e-01])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"x\"])\n",
    "print(data[\"z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26597431-6ce9-4f3f-add6-b6f680acaff9",
   "metadata": {},
   "source": [
    "We can also index the sample with both row number and column label simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d41156e-0722-4c83-90d9-a95cd9f3019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2730993026460248\n",
      "-0.038285954257798564\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(data[\"x\", 0])\n",
    "print(data[1, \"y\"])\n",
    "print(data[\"z\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27da99-e418-49cc-b0cf-6a5bc0b6a389",
   "metadata": {},
   "source": [
    "In general, we recommend indexing with the rule ``data[row, column]`` as opposed to ``data[row][column]`` as it is both faster and more memory efficient.\n",
    "This recommendation applies to all 2-dimensional data structures in TrackStar (i.e. to the ``track`` object as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498d7f4-6d72-44c4-ba9d-5bdf210f1725",
   "metadata": {},
   "source": [
    "#### Linked Arrrays\n",
    "\n",
    "When we indexed our sample with a column label above, we received a particular type of ``array`` as output, namely a ``linked_array``.\n",
    "This class of array-like objects is special in that its memory is \"linked\" with our ``sample`` in the sense that modifying its elements *also* modifies the sample.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35fdea4-578c-475d-84db-13f4b8444a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2730993026460248\n",
      "0.0\n",
      "0.0\n",
      "-0.2730993026460248\n"
     ]
    }
   ],
   "source": [
    "x = data[\"x\"]\n",
    "print(x[0])\n",
    "old_value = x[0]\n",
    "x[0] = 0\n",
    "print(x[0])\n",
    "print(data[\"x\", 0])\n",
    "x[0] = old_value\n",
    "print(data[\"x\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2da06-0963-4acb-851f-69cd46d84ad7",
   "metadata": {},
   "source": [
    "By modifying the ``linked_list`` in the above cell, we have also modified the ``\"x\"`` column of ``data``.\n",
    "Changes to one variable state also affects the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893eb8a-80f8-47da-acf0-bb74c41e35ba",
   "metadata": {},
   "source": [
    "### Where the Measurement Uncertainties Reside\n",
    "\n",
    "When we called ``trackstar.sample`` above, the dictionary keys labeled ``\"err_x\"``, ``\"err_y\"``, and ``\"err_z\"`` were excluded from the sample and not treated as data vector components.\n",
    "TrackStar will treat any keys beginning with ``\"err_\"`` or ending in ``\"_err\"`` as measurement uncertainties and automatically construct diagonalized covariance matrices for each data vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95daf485-b3dc-4663-b966-cea4f08c82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix(\n",
      "    [ 1.0000e-02,  0.0000e+00]\n",
      "    [ 0.0000e+00,  1.0000e-02]\n",
      "    Quantities: [x, y] (in the order of indexing)\n",
      ")\n",
      "covariance matrix(\n",
      "    [ 1.0000e-02,  0.0000e+00,  0.0000e+00]\n",
      "    [ 0.0000e+00,  1.0000e-02,  0.0000e+00]\n",
      "    [ 0.0000e+00,  0.0000e+00,  9.0000e-02]\n",
      "    Quantities: [x, y, z] (in the order of indexing)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data[0].cov)\n",
    "print(data[1].cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449aaa1-9644-4a15-adcc-50b024cbe57b",
   "metadata": {},
   "source": [
    "If we had not specified any measurement uncertainties in our call to ``trackstar.sample``, each element along the diagonal of the covariance matrix would be given an initial value of $1$.\n",
    "We could then modify each data vector's covariance matrix by hand after construction of the sample (see example below and further demonstration in [samples](samples.ipynb) tutorial).\n",
    "\n",
    "The measurement uncertainty on any one quantity can be obtained by taking the square root of the relevant covariance matrix entry along the diagonal.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9af20e0-ec64-4bc3-824b-7763276fbbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(data[0].cov[\"x\"]))\n",
    "print(np.sqrt(data[0].cov[\"x\", \"x\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150a382f-a5d8-48bb-8130-eca90238bbe9",
   "metadata": {},
   "source": [
    "Note that we received the same result with ``data[0].cov[\"x\"]`` and ``data[0].cov[\"x\", \"x\"]``.\n",
    "The covariance matrix is smart enough to know that the user is looking for an element along the diagonal when it is given only one string label or integer index.\n",
    "\n",
    "If any of the quantities covary, that information can be entered now, after the sample has been constructed.\n",
    "Both strings and integers are supported; the appropriate integer corresponds to a component-wise match to the string labels returned by the ``.keys()`` function shown above (i.e. ``data[0].cov[0, 1]`` is the same as ``data[0].cov[\"x\", \"y\"]``).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af55ce3f-93c0-44a8-8d90-6aceab34f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix(\n",
      "    [ 1.0000e-02,  2.0000e-01]\n",
      "    [ 2.0000e-01,  1.0000e-02]\n",
      "    Quantities: [x, y] (in the order of indexing)\n",
      ")\n",
      "covariance matrix(\n",
      "    [ 1.0000e-02,  3.0000e-01]\n",
      "    [ 3.0000e-01,  1.0000e-02]\n",
      "    Quantities: [x, y] (in the order of indexing)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data[0].cov[\"x\", \"y\"] = 0.2\n",
    "print(data[0].cov)\n",
    "data[0].cov[0, 1] = 0.3\n",
    "print(data[0].cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ecb99-3f3f-4501-91f1-26388fe6921a",
   "metadata": {},
   "source": [
    "Because covariance matrices are symmetric by definition, TrackStar has taken the liberty of modifying not only ``data[0].cov[\"x\", \"y\"]`` as requested, but ``data[0].cov[\"y\", \"x\"]`` as well.\n",
    "Any modification to a covariance matrix changes the components both above and below the diagonal automatically.\n",
    "\n",
    "We'll simply change the value back to zero, since our mock data do not include any covariance in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24e6d3e9-65d4-43c6-9d0f-8985e864caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix(\n",
      "    [ 1.0000e-02,  0.0000e+00]\n",
      "    [ 0.0000e+00,  1.0000e-02]\n",
      "    Quantities: [x, y] (in the order of indexing)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data[0].cov[\"y\", \"x\"] = 0\n",
    "print(data[0].cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06593530-5563-4a34-9934-6692543bfada",
   "metadata": {},
   "source": [
    "## A Model to Compare with our Mock\n",
    "\n",
    "Now that we've constructed a ``sample`` (see [above](#a-mock-data-sample)), let's set up our model.\n",
    "We know that the underlying model is the line $x = y = z$ in 3-dimensional space, so we'll start there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c209728-40f7-4d74-ad42-c425b260bb16",
   "metadata": {},
   "source": [
    "### ``trackstar.track``: The Workhorse for Storing Models\n",
    "\n",
    "In the same way that ``trackstar.sample`` does the heavy lifting of data storage, ``trackstar.track`` does the heavy lifting of model storage.\n",
    "Constructing a ``track`` follows a similar procedure as constructing a ``sample``.\n",
    "We simply give it a dictionary containing the predicted values at a sufficiently dense sample of points along the predicted curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f604d3a-e13b-4a59-95e3-bd076e3bd446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track([\n",
      "       x --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       weights --------> [ 1.0000e+00,  1.0000e+00,  1.0000e+00, ...,  1.0000e+00,  1.0000e+00,  1.0000e+00]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "model = trackstar.track({\n",
    "    \"x\": np.linspace(-3, 3, 1000),\n",
    "    \"y\": np.linspace(-3, 3, 1000),\n",
    "    \"z\": np.linspace(-3, 3, 1000)\n",
    "})\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42553e94-d7ce-4ae2-a292-6e96fc3915c3",
   "metadata": {},
   "source": [
    "Note that we gave our ``track`` the **same** column labels as our sample (``\"x\"``, ``\"y\"``, and ``\"z\"``).\n",
    "When we compute the likelihood functions below, TrackStar will look at the column labels in both the data and the model, and then use the ones that match to determine which vector components should be compared with one another.\n",
    "\n",
    "Note also that our ``track`` has automatically picked up an additional column ``\"weights\"``.\n",
    "The weights describe the *predicted* occurrence rates of data vectors as a function of position (see TrackStar science documentation for further details).\n",
    "Their values can also be specified in your call to ``trackstar.track`` by either including them as an additional column with the same label or passing them as a keyword argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56688ed4-7dc9-4c97-9bc8-51d60fb351f6",
   "metadata": {},
   "source": [
    "Many of the features available for ``sample`` objects are also available for ``track`` objects.\n",
    "They also have a ``.keys()`` function, which returns the string labels for different quantities predicted by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aad8a3b2-888b-4740-9947-8fae8ed3a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(model.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f7b62-ada1-483c-a9dc-b2814751b212",
   "metadata": {},
   "source": [
    "They also support the ``len`` function, though they store attributes ``n_vectors`` (the number of points the track is sampled on) and ``dim`` (the number of predicted quantities) as opposed to ``sample``'s ``size``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af1fd3c7-a929-4a5d-859a-ec46f4aeb63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(model))\n",
    "print(model.n_vectors)\n",
    "print(model.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ff9ce-6a39-4e8b-9fc9-c0fff6c89012",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Although ``sample`` objects are allowed to grow in size by adding new data vectors, ``track`` objects do not support additional vectors being added.\n",
    "Every vector at which the model curve is sampled must be supplied to the ``track`` object when it is constructed.\n",
    "If the ``track`` must change, there are two options: 1) a new track can be created, and 2) a larger track can be constructed with placeholder values (e.g. zeros everywhere) that then get modified when the relevant information is available.\n",
    "\n",
    "---\n",
    "\n",
    "``track`` objects can be indexed and sliced with integer indeces to take subsets or coarsened versions of a given track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd77a9e-a595-4352-97b6-1c630fbf831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linked_dictionary{\n",
      "  \"x\": -3.0000e+00,\n",
      "  \"y\": -3.0000e+00,\n",
      "  \"z\": -3.0000e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n",
      "linked_dictionary{\n",
      "  \"x\": -2.9940e+00,\n",
      "  \"y\": -2.9940e+00,\n",
      "  \"z\": -2.9940e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n",
      "track([\n",
      "       x --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ..., -2.9279e+00, -2.9219e+00, -2.9159e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ..., -2.9279e+00, -2.9219e+00, -2.9159e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ..., -2.9279e+00, -2.9219e+00, -2.9159e+00]\n",
      "       weights --------> [ 1.0000e+00,  1.0000e+00,  1.0000e+00, ...,  1.0000e+00,  1.0000e+00,  1.0000e+00]\n",
      "])\n",
      "track([\n",
      "       x --------------> [-3.0000e+00, -2.9880e+00, -2.9760e+00, ...,  2.9700e+00,  2.9820e+00,  2.9940e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9880e+00, -2.9760e+00, ...,  2.9700e+00,  2.9820e+00,  2.9940e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9880e+00, -2.9760e+00, ...,  2.9700e+00,  2.9820e+00,  2.9940e+00]\n",
      "       weights --------> [ 1.0000e+00,  1.0000e+00,  1.0000e+00, ...,  1.0000e+00,  1.0000e+00,  1.0000e+00]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model[1])\n",
    "print(model[:15])\n",
    "print(model[::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1d855-7bad-4bb4-95b8-bbca2af59f64",
   "metadata": {},
   "source": [
    "A ``track`` can also be indexed with strings, or a string and an integer at the same time, just like a ``sample``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0269816-2dc0-41e6-aeba-fa3c68a458ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linked_array([-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00])\n",
      "linked_array([-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00])\n",
      "-3.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(model[\"x\"])\n",
    "print(model[\"y\"])\n",
    "print(model[\"x\", 0])\n",
    "print(model[\"y\", -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc036622-9a3f-4eab-96fd-0a712a888b30",
   "metadata": {},
   "source": [
    "Item assignment also follows familiar standard procedures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "980faea1-0717-4204-8570-addb757aea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linked_dictionary{\n",
      "  \"x\": 4.0000e+00,\n",
      "  \"y\": -3.0000e+00,\n",
      "  \"z\": -3.0000e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n",
      "linked_dictionary{\n",
      "  \"x\": 5.0000e+00,\n",
      "  \"y\": -3.0000e+00,\n",
      "  \"z\": -3.0000e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n",
      "linked_dictionary{\n",
      "  \"x\": 6.0000e+00,\n",
      "  \"y\": -3.0000e+00,\n",
      "  \"z\": -3.0000e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n",
      "linked_dictionary{\n",
      "  \"x\": -3.0000e+00,\n",
      "  \"y\": -3.0000e+00,\n",
      "  \"z\": -3.0000e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "old_value = model[\"x\", 0] # for reassignment at the end of this cell\n",
    "model[\"x\", 0] = 4\n",
    "print(model[0])\n",
    "model[0, \"x\"] = 5\n",
    "print(model[0])\n",
    "model[\"x\"][0] = 6\n",
    "print(model[0])\n",
    "model[0][\"x\"] = old_value\n",
    "print(model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab51c73-2c34-4174-aab8-cb79171feeeb",
   "metadata": {},
   "source": [
    "#### Linked Dictionaries\n",
    "\n",
    "When indexing with an integer, as in some of the above cells, we received a ``linked_dictionary`` as output.\n",
    "The ``linked_dictionary`` is similar to the ``linked_array`` in that it is a ``dict`` whose memory is \"linked\" with the ``track`` itself.\n",
    "Modifications to a ``linked_dictionary`` will also be reflected in the ``track``.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7452f54-565a-4eec-8282-b4707d0f6bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linked_dictionary{\n",
      "  \"x\": -1.0000e+00,\n",
      "  \"y\": -3.0000e+00,\n",
      "  \"z\": -3.0000e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n",
      "track([\n",
      "       x --------------> [-1.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       weights --------> [ 1.0000e+00,  1.0000e+00,  1.0000e+00, ...,  1.0000e+00,  1.0000e+00,  1.0000e+00]\n",
      "])\n",
      "linked_dictionary{\n",
      "  \"x\": -3.0000e+00,\n",
      "  \"y\": -3.0000e+00,\n",
      "  \"z\": -3.0000e+00,\n",
      "  \"weights\": 1.0000e+00,\n",
      "}\n",
      "track([\n",
      "       x --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       weights --------> [ 1.0000e+00,  1.0000e+00,  1.0000e+00, ...,  1.0000e+00,  1.0000e+00,  1.0000e+00]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "zero = model[0]\n",
    "zero[\"x\"] = -1\n",
    "print(zero)\n",
    "print(model)\n",
    "zero[\"x\"] = -3\n",
    "print(zero)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d4341-b35a-45a7-9c5e-c5222f49fb1f",
   "metadata": {},
   "source": [
    "In the above cell, modifications to the variable ``zero`` also modified the ``\"x\"`` column of ``model``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efde35-5b26-4408-88a8-26f64c1d2838",
   "metadata": {},
   "source": [
    "## Computing the Likelihood Function\n",
    "\n",
    "At this point, we are ready to compute the likelihood function.\n",
    "Both individual data vectors and samples have a method ``.loglikelihood()``, which takes in a ``track`` and returns $\\ln L$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bfc3aa5-ab15-4d21-b650-5c84d2c1836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4919181908906873\n",
      "0.8648797774759773\n",
      "-604.6523431201857\n"
     ]
    }
   ],
   "source": [
    "print(data[0].loglikelihood(model))\n",
    "print(data[1].loglikelihood(model))\n",
    "print(data.loglikelihood(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eca574-e87d-454e-9173-8c260583ae3f",
   "metadata": {},
   "source": [
    "TrackStar also allows the likelihood function to be computed for only specific quantities.\n",
    "To do so, simply pass a keyword argument ``quantities`` to the ``loglikelihood`` call, which should be a list of the column labels to use.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee530698-3355-4260-b6d0-a33497a46f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4919181908906873\n",
      "-680.1255641762631\n"
     ]
    }
   ],
   "source": [
    "print(data[0].loglikelihood(model, quantities = [\"x\", \"y\"]))\n",
    "print(data.loglikelihood(model, quantities = [\"y\", \"z\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e4a76-c0b2-4b88-bc5e-ed0abb7719a2",
   "metadata": {},
   "source": [
    "One can also compute the likelihood function for *subsamples* of the data by simply slicing the ``sample``.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07695f60-75c6-40a9-9057-2dcb637f3414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-302.79339321027766\n",
      "-303.49316216816766\n",
      "-301.15918095201823\n"
     ]
    }
   ],
   "source": [
    "print(data[::2].loglikelihood(model))\n",
    "print(data[:50].loglikelihood(model))\n",
    "print(data[-50:].loglikelihood(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c4791-5e55-421e-b669-a6c3a4591370",
   "metadata": {},
   "source": [
    "One can also slice the *model* to compute the likelihood function for only a portion of the predicted ``track``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07bd82a5-8e93-4337-b9af-4a83e96f433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1112.885493526313\n",
      "-739.7014178832077\n",
      "-1065.4797569010773\n"
     ]
    }
   ],
   "source": [
    "print(data.loglikelihood(model[:300]))\n",
    "print(data.loglikelihood(model[400:600]))\n",
    "print(data[::2].loglikelihood(model[-200:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e384d-86d5-4312-9e4c-c9358bd38894",
   "metadata": {},
   "source": [
    "### The Importance of the Weights\n",
    "\n",
    "As mentioned above, the weights quantify the predicted frequency of the data along the curve.\n",
    "In our initial call above, we were not comparing the data with the *true* input model, because the weights do not reflect the fact that the data follow a Gaussian distribution centered on zero.\n",
    "To correct this, we assign the weights accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b8c635d-3e4a-4893-8971-da9977814d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track([\n",
      "       x --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       weights --------> [ 1.0540e-01,  1.0635e-01,  1.0731e-01, ...,  1.0731e-01,  1.0635e-01,  1.0540e-01]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "def gaussian(x, loc = 0, width = 1):\n",
    "    return np.exp(-(x - loc)**2 / (2 * width)**2)\n",
    "\n",
    "for i in range(model.n_vectors):\n",
    "    model[\"weights\", i] = gaussian(model[\"x\", i])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a80892-1b07-427f-b2dc-6a3d37f9e372",
   "metadata": {},
   "source": [
    "And now the likelihood that our sample arose from this model has increased significantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85191315-daf2-458b-9325-db9791c07512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-577.2303901449949\n"
     ]
    }
   ],
   "source": [
    "print(data.loglikelihood(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac301865-af73-4839-9212-1649a0527f0a",
   "metadata": {},
   "source": [
    "### Is my ``track`` densely sampled enough?\n",
    "\n",
    "The model prediction, when stored numerically, is treated as a series of discrete line segments as opposed to a smooth curve.\n",
    "For this reason, it is important to ensure that the ``track`` is sampled at enough points in the observed space.\n",
    "If not, the fact that the computer sees it as a \"jagged\" curve is introducing statistically significant numerical artifacts.\n",
    "\n",
    "One simple way to test this is to simply evaluate the likelihood function for downsampled versions of your ``track`` by slicing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09a9dfd5-396a-4c3f-8c6f-dc9d81d5f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-577.2303901449949\n",
      "-577.2359990061929\n",
      "-577.2476227364217\n",
      "-577.2536459010162\n",
      "-577.2860466536885\n"
     ]
    }
   ],
   "source": [
    "# 2, 4, 5, and 10 chosen because they're divisible by the N = 1000 vectors in our track\n",
    "print(data.loglikelihood(model))\n",
    "print(data.loglikelihood(model[::2]))\n",
    "print(data.loglikelihood(model[::4]))\n",
    "print(data.loglikelihood(model[::5]))\n",
    "print(data.loglikelihood(model[::10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc60b5-c04b-4e94-9703-b78db359386b",
   "metadata": {},
   "source": [
    "In each of the above cases, the returned value of $\\ln L$ changes quite minimally with downsampling, which is an indication that our track is indeed densely sampled enough for the purposes of these calculations.\n",
    "\n",
    "Another way to check this is to pass the keyword argument ``use_line_segment_corrections = True`` to ``loglikelihood``.\n",
    "This parameter is ``False`` by default.\n",
    "When ``True``, TrackStar computes a corrective factor for each individual line segment that accounts for the fact that $\\ln L$ is actually changing smoothly from end to end (see TrackStar's science documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5637c439-63d7-47ae-a1b4-676d5d890860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-577.2303901449949\n",
      "-577.2412190646513\n"
     ]
    }
   ],
   "source": [
    "print(data.loglikelihood(model))\n",
    "print(data.loglikelihood(model, use_line_segment_corrections = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3be9f-440b-4685-8e54-5fde298860c0",
   "metadata": {},
   "source": [
    "We see once again that the inferred values of $\\ln L$ are quite close to one another.\n",
    "Between downsampling by slicing and using corrections for the lengths of individual line segments, the former is much less computationally expensive, but the latter computes the *technically correct* value of $\\ln L$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875ca9f-f19e-4a69-9ddd-56237faa5694",
   "metadata": {},
   "source": [
    "## Parallel Processing\n",
    "\n",
    "If you have enabled TrackStar's parallel processing features (see directions for installing TrackStar), then making use of these features is easy.\n",
    "Simply modify the attribute ``n_threads`` of any ``track`` object and proceed as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8badce79-9fe6-4b4f-95b3-9b4928528410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-577.2303901449948\n"
     ]
    }
   ],
   "source": [
    "model.n_threads = 5\n",
    "print(data.loglikelihood(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625b3cf-f436-4bb6-893f-484b6481b957",
   "metadata": {},
   "source": [
    "## A Note on NaNs in TrackStar\n",
    "\n",
    "Although TrackStar returns ``NaN`` values when a measurement of a particular quantity is not available for a given data vector, these values are not stored in its backend.\n",
    "**They do not correspond to actual blocks of memory stored on your system.**\n",
    "As a consequence, the ``NaN`` values that it returns do not correspond to an existing memory address.\n",
    "For this reason, TrackStar does not allow assignment of ``NaN`` values to real numbers, or vice versa.\n",
    "Such a change would cause TrackStar to infer an incorrect dimensionality of the vector in question, which could result in memory errors.\n",
    "\n",
    "As noted in this tutorial, a new data vector or model ``track`` must be created if the dimensionality of some vector is to change.\n",
    "Alternatively, one can construct a larger vector with its components initialized to some placeholder value (e.g. zero, just not ``NaN``) and then modified thereafter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
