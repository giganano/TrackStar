{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa147aab-bf11-4f5a-aa0c-64b6848834c6",
   "metadata": {},
   "source": [
    "# Your First TrackStar Program\n",
    "\n",
    "In this tutorial, we'll demonstrate a simple use case of TrackStar involving synthetic data to illustrate a typical program.\n",
    "We'll start by simply importing TrackStar and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b2b879-ea47-4765-b644-160ded8406bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesjohnson/Work/Research/lib/public-dev/TrackStar/trackstar/version.py:91: VersionWarning: Using a development version of TrackStar. Be advised that the features in development may exhibit buggy behavior and/or numerical artifacts. We encourage consulting with TrackStar developers.\n",
      "  if self.dev is not None: warnings.warn(\"\"\"\\\n",
      "/Users/jamesjohnson/Work/Research/lib/public-dev/TrackStar/trackstar/version.py:95: VersionWarning: Using an un-released version of TrackStar.\n",
      "  if not self.isreleased: warnings.warn(\"\"\"\\\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trackstar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f493ac1-21bd-4e56-a89d-b220f557266b",
   "metadata": {},
   "source": [
    "## A Mock Data Sample\n",
    "\n",
    "Let's set up our mock sample.\n",
    "For illustrative purposes, we'll keep it simple and straight-forward.\n",
    "\n",
    "We'll take $N = 100$ points along the line $x = y = z$ in 3-dimensional space, following an intrinsic distribution that follows a Gaussian centered on zero (i.e. $\\langle x \\rangle = \\langle y \\rangle = \\langle z \\rangle = 0$) with a standard deviation of $\\sigma = 1$.\n",
    "To demonstrate TrackStar's user-friendliness in fitting non-uniform samples, we'll let only *half* of our data vectors have measurements of $z$.\n",
    "Such instances may arise, e.g., within astrophysics, when not every star has a reliable age measurement.\n",
    "\n",
    "We'll let $x$ and $y$ have measurement uncertainties of $\\sigma_x = \\sigma_y = 0.1$, while each measurement of $z$ will have a more substantial uncertainty of $\\sigma_z = 0.3$.\n",
    "In general, $z$ is a stand-in for some quantity that may be challenging to measure, where real samples may have only a handful of coarse measurements, but the information is nonetheless valuable.\n",
    "\n",
    "Before bringing in TrackStar, let's set up the numbers themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2353dbe6-9635-4e7e-9263-a229de512948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the underlying sample with no measurement uncertainty\n",
    "true_values = np.random.normal(loc = 0, scale = 1, size = 100)\n",
    "\n",
    "# the sampled true values perturbed my measurement uncertainty for x and y\n",
    "x = true_values + np.random.normal(loc = 0, scale = 0.1, size = 100)\n",
    "y = true_values + np.random.normal(loc = 0, scale = 0.1, size = 100)\n",
    "\n",
    "# half of the z measurements are missing\n",
    "z = np.array([true_values[i] + np.random.normal(\n",
    "    loc = 0, scale = 0.3) if i % 2 else float(\"nan\") for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f3cfd-eb52-43c0-b438-aaf2e0225eb6",
   "metadata": {},
   "source": [
    "To construct these arrays, we made use of NumPy's automatic component-wise addition when the arrays are the same length.\n",
    "Let's inspect the first few elements of each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fa4654-5635-4aae-9f46-57098963862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [ 1.11296179  0.6037661  -1.2967496   0.95685588 -1.09202311]\n",
      "y:  [ 1.03205353  0.68087304 -1.35687937  1.15207725 -1.31660893]\n",
      "z:  [       nan 0.51450131        nan 1.03134824        nan]\n"
     ]
    }
   ],
   "source": [
    "print(\"x: \", x[:5])\n",
    "print(\"y: \", y[:5])\n",
    "print(\"z: \", z[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a716539-bcde-4c89-ac7a-6ba5c51ccf0b",
   "metadata": {},
   "source": [
    "TrackStar recognizes ``NaN`` values as missing data, so every other value of $z$ is assigned ``NaN`` accordingly (more on this below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec1291-daa1-4c8d-b2dd-5187bc080962",
   "metadata": {},
   "source": [
    "### ``trackstar.sample``: The Workhorse for Storing Data\n",
    "\n",
    "The workhorse for storing data in TrackStar is ``sample``, which stores data vectors in a dictionary-like manner, using string labels to denote different measured quantities.\n",
    "The most straight-forward way to construct one is to give it a dictionary containing the arrays of each measured quantity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c01fae-40c0-4f9b-b092-4b8ae22ae991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample(\n",
      "    N = 100\n",
      "    x --------------> [ 1.1130e+00,  6.0377e-01, -1.2967e+00, ..., -8.4362e-02, -3.7593e-01,  1.5265e+00]\n",
      "    y --------------> [ 1.0321e+00,  6.8087e-01, -1.3569e+00, ..., -1.1358e-01, -1.6344e-01,  1.6573e+00]\n",
      "    z --------------> [ nan       ,  5.1450e-01,  nan       , ...,  2.6726e-01,  nan       ,  1.7169e+00]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = trackstar.sample({\n",
    "    \"x\": x,\n",
    "    \"y\": y,\n",
    "    \"z\": z,\n",
    "    \"err_x\": 100 * [0.1],\n",
    "    \"err_y\": 100 * [0.1],\n",
    "    \"err_z\": [0.3 if i % 2 else float(\"nan\") for i in range(100)],\n",
    "})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3fdb30-b1e6-4da6-98a5-b06b2f1eb8f0",
   "metadata": {},
   "source": [
    "Let's break down the above call to ``trackstar.sample``.\n",
    "We gave it one parameter, a dictionary, containing each of our arrays ``x``, ``y``, and ``z`` containing our data, each with an intuitive label.\n",
    "Within this dictionary, we also gave it the associated measurement uncertainties ``err_x``, ``err_y``, and ``err_z``.\n",
    "There are additional ways to load your data into a ``sample``, which we'll cover in another tutorial.\n",
    "It is also possible to give your sample additional information on each data vector, separate from the measurements themselves (see [extra information for your ``sample``](#extra-information-for-your-sample) below).\n",
    "\n",
    "What was returned is a data structure with similar behavior to the ``pandas DataFrame`` in that it can be indexed with both row number and column label.\n",
    "By calling the ``.keys()`` instance method, we are able to access the labels that we have given our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bea36af-da35-4b1c-b767-fd82e1e84310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95587103-f985-4cfe-aebd-2d5833594466",
   "metadata": {},
   "source": [
    "TrackStar has recognized the measurement uncertainties for what they are based on their labels in our call to ``trackstar.sample`` above (see [discussion below](#where-the-measurement-uncertainties-reside) for information on where they've gone).\n",
    "\n",
    "We can also access the number of data vectors in our sample by calling either ``len(data)`` or ``data.size``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca44d4ac-40bf-4b45-b13b-991c5c6e305b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21949bac-eee6-4898-878d-7a7c1ce7db24",
   "metadata": {},
   "source": [
    "By indexing with a row number, we get each component of the same data vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5bb126-b819-45ff-b4b5-464391ed04f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datum(\n",
      "    x --------------> 1.1130e+00\n",
      "    y --------------> 1.0321e+00\n",
      ")\n",
      "datum(\n",
      "    x --------------> 6.0377e-01\n",
      "    y --------------> 6.8087e-01\n",
      "    z --------------> 5.1450e-01\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29eb2c9-ebd1-4a8a-9bca-5f34797b1e7a",
   "metadata": {},
   "source": [
    "Note that the ``NaN`` value we entered for our zero'th data vector does not show up here, because TrackStar has recognized this as an indication that there is no measurement.\n",
    "There are some caveats associated with this behavior, which we recommend new users familiarize themselves with (see the [note on NaNs in TrackStar](#an-important-note-on-nans-in-trackstar) below).\n",
    "In short, TrackStar does not allow ``NaN`` values to be changed to numerical values, and vice versa, because they do not correspond to actual blocks of memory storing data vector components.\n",
    "\n",
    "By indexing with a column label, we get the measurements of that quantity for each data vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7c2fa5-4b59-496d-80a8-5f2263cdc9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linked_array([ 1.1130e+00,  6.0377e-01, -1.2967e+00, ..., -8.4362e-02, -3.7593e-01,  1.5265e+00])\n",
      "linked_array([ nan       ,  5.1450e-01,  nan       , ...,  2.6726e-01,  nan       ,  1.7169e+00])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"x\"])\n",
    "print(data[\"z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bcb7cc-fbde-4a36-bce5-06ea9f845f1c",
   "metadata": {},
   "source": [
    "We've received a particular type of ``array`` as output, namely a ``linked_array``.\n",
    "This class of array-like objects is special in that its memory is \"linked\" with our ``sample`` in the sense that modifying its elements *also* modifies the sample.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35fdea4-578c-475d-84db-13f4b8444a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linked_array([ 0.0000e+00,  6.0377e-01, -1.2967e+00, ..., -8.4362e-02, -3.7593e-01,  1.5265e+00])\n",
      "sample(\n",
      "    N = 100\n",
      "    x --------------> [ 0.0000e+00,  6.0377e-01, -1.2967e+00, ..., -8.4362e-02, -3.7593e-01,  1.5265e+00]\n",
      "    y --------------> [ 1.0321e+00,  6.8087e-01, -1.3569e+00, ..., -1.1358e-01, -1.6344e-01,  1.6573e+00]\n",
      "    z --------------> [ nan       ,  5.1450e-01,  nan       , ...,  2.6726e-01,  nan       ,  1.7169e+00]\n",
      ")\n",
      "sample(\n",
      "    N = 100\n",
      "    x --------------> [ 1.1130e+00,  6.0377e-01, -1.2967e+00, ..., -8.4362e-02, -3.7593e-01,  1.5265e+00]\n",
      "    y --------------> [ 1.0321e+00,  6.8087e-01, -1.3569e+00, ..., -1.1358e-01, -1.6344e-01,  1.6573e+00]\n",
      "    z --------------> [ nan       ,  5.1450e-01,  nan       , ...,  2.6726e-01,  nan       ,  1.7169e+00]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = data[\"x\"]\n",
    "old_value = x[0]\n",
    "x[0] = 0\n",
    "print(x)\n",
    "print(data)\n",
    "x[0] = old_value\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1d209-740f-44d0-a21a-3cabd3df3fb6",
   "metadata": {},
   "source": [
    "By modifying the ``linked_list`` that we received by indexing ``data[\"x\"]``, we are also modifying ``data`` itself.\n",
    "Changes to one of these variables also affects the other.\n",
    "\n",
    "We can also index the sample with both row number and column label simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d41156e-0722-4c83-90d9-a95cd9f3019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1129617874098852\n",
      "0.6808730387738765\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(data[\"x\", 0])\n",
    "print(data[1, \"y\"])\n",
    "print(data[\"z\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27da99-e418-49cc-b0cf-6a5bc0b6a389",
   "metadata": {},
   "source": [
    "In general, we recommend indexing with the rule ``data[row, column]`` as opposed to ``data[row][column]`` as it is both faster and more memory efficient.\n",
    "For non-uniform samples, the ``data[row][column]`` rule may also result in a seemingly erroneous ``KeyError`` if a particular data vector does not have a measurement for the quantity in question (see [further discussion](#beware-when-indexing-non-uniform-samples) below), whereas ``data[row, column]`` would return a ``NaN`` value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893eb8a-80f8-47da-acf0-bb74c41e35ba",
   "metadata": {},
   "source": [
    "### Where the Measurement Uncertainties Reside\n",
    "\n",
    "When we called ``trackstar.sample`` above, the dictionary keys labeled ``\"err_x\"``, ``\"err_y\"``, and ``\"err_z\"`` were excluded from the sample and not treated as data vector components.\n",
    "TrackStar will treat any keys beginning with ``\"err_\"`` or ending in ``\"_err\"`` as measurement uncertainties and automatically construct diagonalized covariance matrices for each data vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95daf485-b3dc-4663-b966-cea4f08c82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix(\n",
      "    [ 1.0000e-02,  0.0000e+00]\n",
      "    [ 0.0000e+00,  1.0000e-02]\n",
      "    Quantities: [x, y] (in the order of indexing)\n",
      ")\n",
      "covariance matrix(\n",
      "    [ 1.0000e-02,  0.0000e+00,  0.0000e+00]\n",
      "    [ 0.0000e+00,  1.0000e-02,  0.0000e+00]\n",
      "    [ 0.0000e+00,  0.0000e+00,  9.0000e-02]\n",
      "    Quantities: [x, y, z] (in the order of indexing)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data[0].cov)\n",
    "print(data[1].cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449aaa1-9644-4a15-adcc-50b024cbe57b",
   "metadata": {},
   "source": [
    "If we had not specified any measurement uncertainties in our call to ``trackstar.sample``, each element along the diagonal of the covariance matrix would be given an initial value of $1$.\n",
    "We could then modify each data vector's covariance matrix by hand after construction of the sample (see description below).\n",
    "\n",
    "The measurement uncertainty on any one quantity can be obtained by taking the square root of the relevant covariance matrix entry along the diagonal.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9af20e0-ec64-4bc3-824b-7763276fbbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(data[0].cov[\"x\"]))\n",
    "print(np.sqrt(data[0].cov[\"x\", \"x\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150a382f-a5d8-48bb-8130-eca90238bbe9",
   "metadata": {},
   "source": [
    "Note that we received the same result with ``data[0].cov[\"x\"]`` and ``data[0].cov[\"x\", \"x\"]``.\n",
    "The covariance matrix is smart enough to know that the user is looking for an element along the diagonal when it is given only one string label or integer index.\n",
    "\n",
    "If any of the quantities covary, that information can be entered now, after the sample has been constructed.\n",
    "Both strings and integers are supported; the appropriate integer corresponds to a component-wise match to the string labels returned by the ``.keys()`` function shown above (i.e. ``data[0].cov[0, 1]`` is the same as ``data[0].cov[\"x\", \"y\"]``).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af55ce3f-93c0-44a8-8d90-6aceab34f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix(\n",
      "    [ 1.0000e-02,  2.0000e-01]\n",
      "    [ 2.0000e-01,  1.0000e-02]\n",
      "    Quantities: [x, y] (in the order of indexing)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data[0].cov[\"x\", \"y\"] = 0.2\n",
    "print(data[0].cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ecb99-3f3f-4501-91f1-26388fe6921a",
   "metadata": {},
   "source": [
    "Because covariance matrices are symmetric by definition, TrackStar has taken the liberty of modifying not only ``data[0].cov[\"x\", \"y\"]`` as requested, but ``data[0].cov[\"y\", \"x\"]`` as well.\n",
    "Any modification to a covariance matrix changes the components both above and below the diagonal automatically.\n",
    "\n",
    "We'll simply change the value back to zero, since our mock data do not include any covariance in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e6d3e9-65d4-43c6-9d0f-8985e864caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix(\n",
      "    [ 1.0000e-02,  0.0000e+00]\n",
      "    [ 0.0000e+00,  1.0000e-02]\n",
      "    Quantities: [x, y] (in the order of indexing)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data[0].cov[\"y\", \"x\"] = 0\n",
    "print(data[0].cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59acfce9-a146-4fb8-b690-daad327ae0fa",
   "metadata": {},
   "source": [
    "### Extra Information for your ``sample``\n",
    "\n",
    "It is often useful for data to have additional information available that does not necessarily correspond to the measurements themselves.\n",
    "One such example would be ID numbers for each data vector.\n",
    "In the context of astrophysics, these may be, e.g., unique identifiers for stars from a given survey or catalog.\n",
    "In the same way that ``NaN`` values represent a lack of data for a particular data vector, ``None`` values can be used to indicate a lack of extra information.\n",
    "\n",
    "TrackStar allows your ``sample`` to store additional data through its ``extra`` attribute, which is a subclass of ``dict``.\n",
    "To demonstrate this, we'll give each of our data vectors a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c845f12e-3186-4df4-add6-f6716c30f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.size):\n",
    "    data[i].extra[\"id\"] = \"name\" + str(i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2f8c7-bcd2-4896-9d8a-5c8bffe8d861",
   "metadata": {},
   "source": [
    "Extra information can also be included in your original call to ``trackstar.sample`` by including it as a keyword argument.\n",
    "Simply give it a dictionary that follows the rule ``extra = {key1: value1, key2: value2}`` where ``key1`` and ``key2`` are string labels and ``value1`` and ``value2`` are array-like objects of the appropriate length.\n",
    "\n",
    "The above for-loop is functionally equivalent to going through the ``data.extra`` attribute to modify each entry in the sample in one fell swoop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cbe768b-d636-43e1-b3aa-7c7aa815dadf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample(\n",
      "    N = 100\n",
      "    x --------------> [ 1.1130e+00,  6.0377e-01, -1.2967e+00, ..., -8.4362e-02, -3.7593e-01,  1.5265e+00]\n",
      "    y --------------> [ 1.0321e+00,  6.8087e-01, -1.3569e+00, ..., -1.1358e-01, -1.6344e-01,  1.6573e+00]\n",
      "    z --------------> [ nan       ,  5.1450e-01,  nan       , ...,  2.6726e-01,  nan       ,  1.7169e+00]\n",
      "\n",
      "    extra\n",
      "    -----\n",
      "    id -------------> [      name1,       name2,       name3, ...,      name98,      name99,     name100]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data.extra[\"id\"] = [\"name%d\" % (i + 1) for i in range(data.size)]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa07e9-429c-4a24-87a7-4b71cf5b0395",
   "metadata": {},
   "source": [
    "And the information can be accessed by indexing in various intuitive ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "215cc937-8c30-4626-978d-c2541155e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name1\n",
      "name1\n",
      "name1\n"
     ]
    }
   ],
   "source": [
    "print(data[0].extra[\"id\"])\n",
    "print(data.extra[\"id\", 0])\n",
    "print(data.extra[0][\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06593530-5563-4a34-9934-6692543bfada",
   "metadata": {},
   "source": [
    "## A Model to Compare with our Mock\n",
    "\n",
    "Now that we've constructed a ``sample`` (see [above](#a-mock-data-sample)), let's set up our model.\n",
    "We know that the underlying model is the line $x = y = z$ in 3-dimensional space, so we'll start there.\n",
    "\n",
    "### ``trackstar.track``: The Workhorse for Storing Models\n",
    "\n",
    "In the same way that ``trackstar.sample`` does the heavy lifting of data storage, ``trackstar.track`` does the heavy lifting of model storage.\n",
    "Constructing a ``track`` follows a similar procedure as constructing a ``sample``.\n",
    "We simply give it a dictionary containing the predicted values at a sufficiently dense sample of points along the predicted curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f604d3a-e13b-4a59-95e3-bd076e3bd446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track([\n",
      "       x --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       weights --------> [ 1.0000e+00,  1.0000e+00,  1.0000e+00, ...,  1.0000e+00,  1.0000e+00,  1.0000e+00]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "model = trackstar.track({\n",
    "    \"x\": np.linspace(-3, 3, 1000),\n",
    "    \"y\": np.linspace(-3, 3, 1000),\n",
    "    \"z\": np.linspace(-3, 3, 1000)\n",
    "})\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42553e94-d7ce-4ae2-a292-6e96fc3915c3",
   "metadata": {},
   "source": [
    "Note that we gave our track the **same** column labels as our sample (``\"x\"``, ``\"y\"``, and ``\"z\"``).\n",
    "When we compute the likelihood functions below, TrackStar will look at the column labels in both the data and the model, and then use the ones that match to determine which vector components should be compared with one another.\n",
    "\n",
    "Note also that our track has automatically picked up an additional column ``\"weights\"``.\n",
    "The weights describe the *predicted* occurrence rates of data vectors as a function of position.\n",
    "Their values can also be specified in your call to ``trackstar.track`` by either including them as an additional column with the same label or passing them as a keyword argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efde35-5b26-4408-88a8-26f64c1d2838",
   "metadata": {},
   "source": [
    "## Computing the Likelihood Function\n",
    "\n",
    "At this point, we are ready to compute the likelihood function.\n",
    "Both individual data vectors and samples have a method ``.loglikelihood()``, which takes in a ``track`` and returns $\\ln L$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bfc3aa5-ab15-4d21-b650-5c84d2c1836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5473002080248064\n",
      "0.9119898647390509\n",
      "-604.291641106799\n"
     ]
    }
   ],
   "source": [
    "print(data[0].loglikelihood(model))\n",
    "print(data[1].loglikelihood(model))\n",
    "print(data.loglikelihood(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e384d-86d5-4312-9e4c-c9358bd38894",
   "metadata": {},
   "source": [
    "### The Importance of the Weights\n",
    "\n",
    "As mentioned above, the weights quantify the predicted frequency of the data along the curve.\n",
    "In our initial call above, we were not comparing the data with the *true* input model, because the weights do not reflect the fact that the data follow a Gaussian distribution centered on zero.\n",
    "To correct this, we assign the weights accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8c635d-3e4a-4893-8971-da9977814d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track([\n",
      "       x --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       y --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       z --------------> [-3.0000e+00, -2.9940e+00, -2.9880e+00, ...,  2.9880e+00,  2.9940e+00,  3.0000e+00]\n",
      "       weights --------> [ 1.0540e-01,  1.0635e-01,  1.0731e-01, ...,  1.0731e-01,  1.0635e-01,  1.0540e-01]\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "def gaussian(x, loc = 0, width = 1):\n",
    "    return np.exp(-(x - loc)**2 / (2 * width)**2)\n",
    "\n",
    "for i in range(model.n_vectors):\n",
    "    model[\"weights\", i] = gaussian(model[\"x\", i])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a80892-1b07-427f-b2dc-6a3d37f9e372",
   "metadata": {},
   "source": [
    "And now the likelihood that our sample arose from this model has increased dramatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85191315-daf2-458b-9325-db9791c07512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-575.6432843179554\n"
     ]
    }
   ],
   "source": [
    "print(data.loglikelihood(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c395eeb-7b05-4dd3-a7f1-2be18d54ef5b",
   "metadata": {},
   "source": [
    "### Computing the Likelihood for Subsamples of the Data\n",
    "\n",
    "You can omit quantities through the ``quantities`` keyword arg, slice the model, slice the track, and call with the same signature.\n",
    "Allows you to quantitatively answer your question *\"where is the information coming from?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637c439-63d7-47ae-a1b4-676d5d890860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db213a4c-b432-452b-9ca2-3a178121b904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b676ad8-1570-4e36-a26c-08b23d368c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365096fd-3b0c-471d-a871-c7d7a045963b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db7704-4259-4264-8c74-1e26bc2529d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0625b3cf-f436-4bb6-893f-484b6481b957",
   "metadata": {},
   "source": [
    "## An Important Note on NaNs in TrackStar\n",
    "\n",
    "While TrackStar returns ``nan`` values when it does not have a measurement for a particular quantity, they are not stored in the backend. As a consequence, **they do not actually correspond to actual blocks of memory stored on your system**.\n",
    "The ``nan`` values that it returns therefore do not correspond to an existing memory address; instead, TrackStar simply tracks which measurements are available for which quantities, so it knows when it should return a ``nan``.\n",
    "\n",
    "Based on this behavior, TrackStar does not allow users to change ``nan`` values to real numbers or vice versa. Doing so would change the dimensionality of the stored data and result in memory errors.\n",
    "If new measurements are to be added to a data vector that already exists as a ``datum`` variable, one must simply make a new ``datum``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f990fb-b9f4-44b1-bcda-afb0d128b495",
   "metadata": {},
   "source": [
    "### Beware when Indexing Non-Uniform Samples\n",
    "\n",
    "When working with data in which some vectors do not have measurements for every quantity, as is the case in our [mock sample](#a-mock-data-sample) in the $z$-direction, a ``KeyError`` may arise if one is not careful.\n",
    "The notion that *no memory is allocated for the missing quantities* is central to this behavior.\n",
    "To demonstrate this behavior, consider the block of code below, where we ask TrackStar for the measurement of $z$ associated with our $0$'th datum, which has no such measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1e96c4b-673e-4db4-a2c2-368db7108027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Unrecognized datum label: z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32mtrackstar/core/datum.pyx:133\u001b[0m, in \u001b[0;36mtrackstar.core.datum.datum.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unrecognized datum label: z'"
     ]
    }
   ],
   "source": [
    "print(data[\"z\", 0])\n",
    "print(data[0, \"z\"])\n",
    "print(data[\"z\"][0])\n",
    "print(data[0][\"z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4d297-5f21-42f9-8e8a-4d6ff1b750e4",
   "metadata": {},
   "source": [
    "The first three times we indexed our sample, we got the expected ``nan`` value back.\n",
    "However, a ``KeyError`` was raised the fourth time.\n",
    "The difference between the fourth line and the preceding lines is that we *first* asked TrackStar for the $0$th datum, and *then* asked that datum for its measurement of $z$, for which there is none.\n",
    "Unaware that it is embedded in a sample that contains measurements of these quantities, it raises an error.\n",
    "In the third line, we first asked the sample as a whole for every $z$ measurement, so TrackStar knew to include a ``nan`` for the $0$'th datum.\n",
    "In the second and third lines, we gave the sample both ``\"z\"`` and ``0`` simultaneously, so it immediately knew that we were asking for a measurement that does not exist.\n",
    "\n",
    "As discussed above, it is both faster and more memory efficient to index TrackStar data with all values simultaneously.\n",
    "Consequently, ``sample[0, \"z\"]`` and ``sample[\"z\", 0]`` are recommended over ``sample[\"z\"][0]`` anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7d72e-991d-496d-8e3c-aa72655414a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
